一、cpu资源
默认情况下，容器可以无限制地使用主机的cpu资源，可以通过设置参数来进行限制。一般都采用Linux默认的CFS调度法，当然也可以使用实时调度。CFS调度可以使用如下参数来进行限制：

    1、--cpus=<value>：限制容器可以使用多少cpu，可以设置为小数，例如可以设置--cpus=1.5。该选项代表使用cpu的百分比，而不是具体的个数。例如主机一共有四个cpu，设--cpus=2，不代表有两个cpu被100%占用，另外两个完全空闲，可能四个cpu各被占用50%。docker1.13版本开始支持该选项，之前的版本配合使用--cpu-period和--cpu-quota选项，设置--cpus=1.5相当于设置--cpu-period=100000和--cpu-quota=150000。
    2、--cpu-period=<value>：指定cpu CFS的周期，通常和--cpu-quota一起使用，单位是us。默认值是100毫秒，但是大多用户一般不会改变这个值，使用--cpus=<value>更加方便。
    3、--cpu-quota=<value>：指定容器在一个cpu CFS调度周期中可以使用cpu的时间，单位是us。通常和--cpu-period一起使用，一般使用--cpus=<value>更加方便。
    4、--cpuset-cpus=<value>：限制容器可以使用指定的cpu，如果有多个cpu，可以以逗号分隔或者使用连字符进行指定，比如1，3代表使用第1和第3个cpu，0-3代表使用编号为0，1，2，3的cpu。
    5、--cpu-shares=<value>：容器使用cpu的权重，默认值是1024，不设置或者将其设置为0都将使用默认值，数值越大权重越大。这是一个软限制，只有cpu资源不足时才生效。当cpu资源充足时，各个容器可以在不超过资源限制的条件下使用cpu资源；当cpu资源不足，并有多个容器竞争cpu资源时，系统会根据每个容器的权值和所有容器权值的比例来给容器分配 cpu使用时间，如果容器A设置为--cpu-shares=2048，容器B设置为--cpu-shares=1024，容器A会被分配大约66%的cpu时间，容器B被分配大约33%的cpu时间。

限制cpu资源

    [root@k8snode2 ~]# docker run -itd --name cpu-cgroups --rm --cpus 0.5 centos:latest 
    62adaf7b777dac853b396052e97992cecac9c6d42cf3d390e20c96296cd613cc
    [root@k8snode2 ~]# docker exec -it cpu-cgroups  bash
    限制cpu后执行lscpu查看还是2核心，这是因为容器会挂载宿主机的/sys/fs/cgroup目录，可以让容器只看到自身只能使用的cpu，？？？？
    [root@62adaf7b777d /]# lscpu 
    Architecture:        x86_64
    CPU op-mode(s):      32-bit, 64-bit
    Byte Order:          Little Endian
    CPU(s):              2
    On-line CPU(s) list: 0,1
    Thread(s) per core:  1
    Core(s) per socket:  2
    Socket(s):           1
    NUMA node(s):        1
    Vendor ID:           GenuineIntel
    CPU family:          6
    Model:               140
    Model name:          11th Gen Intel(R) Core(TM) i5-1135G7 @ 2.40GHz
    Stepping:            1
    CPU MHz:             2419.202
    BogoMIPS:            4838.40
    Hypervisor vendor:   VMware
    Virtualization type: full
    L1d cache:           48K
    L1i cache:           32K
    L2 cache:            1280K
    L3 cache:            8192K
    NUMA node0 CPU(s):   0,1
    Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon rep_good nopl xtopology
    tsc_reliable nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 arat avx512vbmi umip pku ospke avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq movdiri movdir64b md_clear spec_ctrl intel_stibp flush_l1d arch_capabilities
限制再只能使用指定的cpu0

    [root@k8snode2 ~]# docker run -itd --name cpu-cgroups --rm --cpuset-cpus 0 centos:latest 
限制再只能使用指定的cpu0，cpu1

    [root@k8snode2 ~]# docker run -it --name cpu-cgroups --rm --cpuset-cpus 0,1 centos:latest
限制再只能使用指定的cpu0-1

    [root@k8snode2 ~]# docker run -it --name cpu-cgroups --rm --cpuset-cpus 0-1 centos:latest 


二、内存资源

    1、-m= <value>或--memory=<value>：内存限制，最小值为6m。
    2、--memory-swap =<value>：内存+交换分区的总限制，只有设置了-m之后，这个参数才有意义。如果--memory=300m，--memory-swap=1g,那么容器可以使用300m的内存和700m的交换分区；如果设置的数值和--memory一样，那么容器无法使用交换分区；如果该值没有设置，容器最多可以使用和--memory一样大的交换分区；如果该值设置为0，那么相当于没有设置；如果设置为-1，可以使用的交换分区大小无限制。此外，可以用docker stats containerID来查看某个容器的运行状态。
    3、--memory-swappiness=<value>：默认情况下，容器的内核可以交换出一定比例的匿名页，此参数用来设置可用的比例。数值在0-100之间，0代表关闭匿名页交换，100表示所有匿名页都可以交换。如果没有设置该值，该值默认从父进程继承而来。
    4、--memory-reservation=<value>：是一种软性限制，确保容器不会长时间占用超过--memory-reservation限制的内存大小，但是不保证时时刻刻都不超过该限制值。当该值比--memory小时，在主机内存资源紧张时，会强迫容器的内存占用不超过该值；没有设置时，该值和--memory的值相同；将其设置为0或者大于--memory时，相当于没有设置。
    5、--kernel-memory=<value>：容器可以使用的最大内核内存值，最小值为4m。
    6、--oom-kill-disable：默认情况下，OOM错误发生时，主机会杀死容器进程来获取更多内存。使用该选项，可以避免容器进程被杀死，但是应该在设置了-m/--memory参数之后才使用该选项，不然不限制容器内存使用，却禁止主机杀死容器进程，当出现OOM错误时，系统会杀死主机进程来获取内存。


限制内存为200m

    [root@k8snode2 ~]# docker run -it --rm --name mem-cgroups -m=200m centos:latest
    [root@k8snode2 ~]# docker run -it --rm --name mem-cgroups --memory=200m centos:latest #和上面的效果一致
stats查看容器状态

    [root@k8snode2 ~]# docker stats mem-cgroups 
    CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT   MEM %               NET I/O             BLOCK I/O           PIDS
    9e433fcb1f3c        mem-cgroups         0.00%               540KiB / 200MiB     0.26%               656B / 0B           0B / 0B             1
使用progrium/stress镜像测试Docker配额限制
拉去镜像

    [root@k8snode2 ~]# docker pull progrium/stress
限制内存为200m，由于超过了容器最大内存会直接报错退出。(一般没有禁用swap的情况下，超过--memory-swap的大小时才会超过最大内存，如果没有指定--memory-swap则超过-m或者--memory指定内存的2倍才会超好最大内存然后报错退出。此处因为禁用了swap，所以超过了-m指定的内存大小就退出了)

    [root@k8snode2 ~]# docker run -it --rm --name mem-cgroups --memory=200m progrium/stress --vm 1 --vm-bytes 200m
    stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
    stress: dbug: [1] using backoff sleep of 3000us
    stress: dbug: [1] --> hogvm worker 1 [6] forked
    stress: dbug: [6] allocating 209715200 bytes ...
    stress: dbug: [6] touching bytes in strides of 4096 bytes ...
    stress: FAIL: [1] (416) <-- worker 6 got signal 9
    stress: WARN: [1] (418) now reaping child worker processes
    stress: FAIL: [1] (422) kill error: No such process
    stress: FAIL: [1] (452) failed run completed in 0s
    [root@k8snode2 ~]#
查看messages日志，可以看到发生了oom，容器进程被杀死了 

    [root@k8snode2 ~]# tailf /var/log/messages
    Nov  1 14:41:27 k8snode2 kernel: memory+swap: usage 204800kB, limit 409600kB, failcnt 0
    Nov  1 14:41:27 k8snode2 kernel: kmem: usage 0kB, limit 9007199254740988kB, failcnt 0
    Nov  1 14:41:27 k8snode2 kernel: Memory cgroup stats for /system.slice/docker-c5352f36e6cedf945a0337d4fc9e0bdc71897b5f343f3a032b48343d9ed6018d.scope: cache:0KB rss:204800KB rss_huge:24576KB mapped_file:0
    KB swap:0KB inactive_anon:0KB active_anon:204748KB inactive_file:0KB active_file:0KB unevictable:0KBNov  1 14:41:27 k8snode2 kernel: [ pid ]   uid  tgid total_vm      rss nr_ptes swapents oom_score_adj name
    Nov  1 14:41:27 k8snode2 kernel: [109432]     0 109432     1826      106       8        0             0 stress
    Nov  1 14:41:27 k8snode2 kernel: [109457]     0 109457    53027    51223     108        0             0 stress
    Nov  1 14:41:27 k8snode2 kernel: Memory cgroup out of memory: Kill process 109457 (stress) score 1002 or sacrifice child
    Nov  1 14:41:27 k8snode2 kernel: Killed process 109457 (stress), UID 0, total-vm:212108kB, anon-rss:204636kB, file-rss:256kB, shmem-rss:0kB
禁止容器发生oom时，被主机杀死容器进程

    [root@k8snode2 ~]# docker run -it --rm --name mem-cgroups --memory=200m --oom-kill-disable progrium/stress --vm 1 --vm-bytes 200m
    stress: info: [1] dispatching hogs: 0 cpu, 0 io, 1 vm, 0 hdd
    stress: dbug: [1] using backoff sleep of 3000us
    stress: dbug: [1] --> hogvm worker 1 [6] forked
    stress: dbug: [6] allocating 209715200 bytes ...
    stress: dbug: [6] touching bytes in strides of 4096 bytes ...

此时查看容器的内存使用率

        [root@k8snode2 ~]# docker stats mem-cgroups 
        CONTAINER ID        NAME                CPU %               MEM USAGE / LIMIT   MEM %               NET I/O             BLOCK I/O           PIDS
        5cbf4379b01f        mem-cgroups         0.00%               200MiB / 200MiB     100.00%             656B / 0B           0B / 0B             2

三、I/O资源

    --device-read-bps：限制读某个设备的bps

    --device-write-bps：限制写某个设备的bps

    --device-read-iops：限制读某个设备的iops

    --device-write-iops：限制写某个设备的iops

