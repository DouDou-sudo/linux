生产环境中，一般不会在新节点加入ceph集群后，立即开始数据回填，这样会影响集群性能。所以我们需要设置一些标志位，来完成这个目的

ceph osd set noin   # 设置标志位
ceph osd set nobackfill # 设置不回填数据标志

在用户访问的非高峰时，取消这些标志位，集群开始在平衡任务

ceph osd unset noin         # 取消设置标志位
ceph osd unset nobackfill   # 取消不回填数据标志



一  删除 坏的 osd

ceph -s

查看osd
ceph osd tree

1.1
停止此osd进程
systemctl stop  ceph-osd@0
1.2
下线osd
ceph osd out 0
1.3
将osd.0踢出集群
ceph osd crush remove osd.0
1.4
ceph auth del osd.0
ceph osd rm 0

1.5
df -h
lsblk -l
ll /var/lib/ceph/osd/ceph-0

1.6
此时我们将损坏的磁盘 umount，结束。
ceph-disk zap /dev/sdb
umount /var/lib/ceph/osd/ceph-0
dmsetup remove_all
ceph-disk zap /dev/sdb


二 添加新的osd


1、准备磁盘（新增节点操作）
[root@node1 ~]# yum install ceph ceph-radosgw -y
[root@node1 ~]# parted /dev/sdb mklabel gpt -s
[root@node1 ~]# ceph-volume lvm zap /dev/sdb

2、添加osd(主节点操作)
[root@node1 ~]# ceph-deploy osd create --data /dev/sdb node1

ceph osd tree
ceph -s








