

1
在其他正常的节点将故障节点进行移除   node4 
ceph orch host rm node4 --offline --force


2
节点初始化操作
将node4节点即故障节点更换新的系统盘并重新安装系统，重装后node4主机名我修改成了node1,并更换了新的ip，在三台ceph节点上重新添加hosts解析
192.168.1.1 node1
192.168.1.2 node2
192.168.1.3 node3


3
将公钥添加至新主机 node1
ssh-copy-id -f -i /etc/ceph/ceph.pub node1

4
安装docker环境  （省略）
安装cephadm以及ceph-common
# curl --silent --remote-name --location https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm
# chmod +x cephadm
# ./cephadm add-repo --release pacific
# ./cephadm install
# ./cephadm install  ceph-common

5
在ceph集群添加新主机  node1
[root@node2 ~]# ceph orch host add node1
Added host 'node1'

ceph orch host ls 

6  重要 必须打标签
ceph orch host label add node1 _admin
或者在添加节点时就可以把标签添加上
ceph orch host add node1 --labels=_admin

7
删除osd的操作如下：

ceph orch ps --daemon_type osd
#查看osd对应的容器id，先停止容器,我这里没有osd容器启动，所以这步可以忽略
ceph osd out 2
ceph osd crush remove osd.2
ceph auth del osd.2
ceph osd rm 2

上步只是在ceph删除，还需要在磁盘上进行格式化

# 显示当前设备的状态
# dmsetup status
# 删除所有映射关系
# dmsetup remove_all
# 格式化刚才删除的osd所在磁盘
mkfs -t ext4 /dev/vdb

8
重新添加osd
ceph orch daemon add osd node1:/dev/vdb

ceph -s

























